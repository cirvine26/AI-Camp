{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"},"colab":{"name":"Kaggle Comp.ipynb","version":"0.3.2","provenance":[{"file_id":"1idHWIUhRhvjouwfksBu0mGakUWUtxN3B","timestamp":1566569606526}],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Tt8pZVd8HHMy","colab_type":"code","colab":{}},"source":["# COMMENT OUT FOR KAGGLE\n","\n","#!mkdir /content/input\n","#!mkdir /content/input/evaluate\n","#!mkdir /content/input/natural_images\n","#!wget \"https://ai-camp-content.s3.amazonaws.com/natural_images.zip\" -P /content/input\n","#!wget \"https://ai-camp-content.s3.amazonaws.com/evaluate.zip\" -P /content/input\n","#!unzip /content/input/natural_images.zip -d /content/input/natural_images \n","#!unzip /content/input/evaluate.zip -d /content/input/evaluate "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","id":"il_1FdSbHFXn","colab_type":"code","colab":{}},"source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import keras as ks # neural network models\n","\n","# For working with images\n","import cv2 as cv\n","import matplotlib.image as mpimg\n","import tqdm\n","\n","# Potentially useful tools - you do not have to use these\n","from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n","from sklearn.model_selection import train_test_split\n","from keras.utils import to_categorical\n","from keras.models import Sequential, Model \n","from keras import applications\n","from keras import optimizers\n","from keras.layers import Activation, Convolution2D, Flatten, Dense, Dropout, MaxPooling2D\n","from keras.optimizers import SGD\n","\n","import os\n","\n","# Input data files are available in the \"../input/\" directory.\n","# Any results you write to the current directory are saved as output."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Uz1B4soSHFXw","colab_type":"code","colab":{}},"source":["# CONSTANTS\n","# You may not need all of these, and you may find it useful to set some extras\n","\n","CATEGORIES = ['airplane','car','cat','dog','flower','fruit','motorbike','person']\n","\n","IMG_WIDTH = 100\n","IMG_HEIGHT = 100\n","TRAIN_PATH = '/content/input/natural_images/natural_images/'\n","TEST_PATH = '/content/input/evaluate/evaluate/'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","id":"pFpyYX3KHFX0","colab_type":"code","colab":{}},"source":["# To find data:\n","folders = os.listdir(TRAIN_PATH)\n","\n","images = []\n","\n","#Generates labels based on the folder they have come from \n","for folder in folders:\n","    files = os.listdir(TRAIN_PATH + folder)\n","    images += [(folder, file, folder + '/' + file) for file in files]\n","\n","image_locs = pd.DataFrame(images, columns=('class','filename','file_loc'))\n","\n","# data structure is three-column table\n","# first column is class, second column is filename, third column is image address relative to TRAIN_PATH\n","image_locs.head()\n","\n","#Declare a numpy array to hold all \n","image_class = np.array(image_locs['class'])\n","\n","#Split the data into training and testimg data\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5fCVrXJ6HFX3","colab_type":"text"},"source":["### Over to you\n","\n","Now you must create your own solution to the problem. To get the file containing your results, you have to `commit` the kernel and then navigate to [kaggle.com/kernels](https://www.kaggle.com/kernels/), and the 'Your Work' tab, where you will find a list of your notebooks. Click on it and scroll down to the `Output` section."]},{"cell_type":"code","metadata":{"id":"CMUHbNZXHFX4","colab_type":"code","colab":{}},"source":["#Consider using a KNN algorithm \n","\n","#define the number of classes and the desired size of each image \n","num_categories = len(CATEGORIES)\n","image_width = 150\n","image_height = 150 #potential variable to be changed \n","\n","#Define an image data generator that will diversify the training data:\n","datagen = ImageDataGenerator(horizontal_flip = True, rescale = 1./255, rotation_range = 360)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bfyhi9f0HFX6","colab_type":"code","colab":{}},"source":["#Create the model:\n","\n","def create_model():\n","  #Channels first to force the (Height, Width, Depth) format \n","  data_format = 'channels_first'\n","  \n","  #create a sequential model \n","  model = Sequential()\n","  \n","  #Add layers \n","  #Convolution layer to identify key features \n","  model.add(Convolution2D(32, (3, 3), input_shape=(image_width, image_height, 3)))\n","  \n","  #Activation layer of relu to map all negative values to 0 and keep all positive ones\n","  model.add(Activation('relu'))\n","  \n","  #Pooling layer to reduce the dimensions of the image \n","  model.add(MaxPooling2D(data_format=data_format, pool_size=(2,2)))\n","  \n","  #Add another convolution layer\n","  model.add(Convolution2D(32, (3, 3), input_shape=(image_width, image_height, 3)))\n","  \n","  #Add another relu activation \n","  model.add(Activation('relu'))\n","  \n","  #Add max pooling\n","  model.add(MaxPooling2D(data_format=data_format, pool_size=(2,2)))\n","  \n","  #Add another convolution layer\n","  #model.add(Convolution2D(32, (3,3), input_shape=(image_width, image_height, 3)))\n","    \n","  #Add another activation of relu\n","  #model.add(Activation('relu'))\n","    \n","  #Add a max pooling layer\n","  #model.add(MaxPooling2D(data_format=data_format, pool_size=(2,2)))\n","  \n","  #Add a flatten layer to reduce the output from the previous layer into an array with dimension 1 \n","  model.add(Flatten())\n","  \n","  #Add a generic dense layer \n","  model.add(Dense(32))\n","  \n","  #Add activation \n","  model.add(Activation('relu'))\n","  \n","  #Add a dropout layer \n","  model.add(Dropout(0.5))\n","  \n","  #Add a final dense layer \n","  model.add(Dense(8))\n","  \n","  #Add sigmoid activation\n","  model.add(Activation('sigmoid'))\n","  \n","  #Compile the model\n","  model.compile(optimizer = 'SGD',\n","               loss = 'categorical_crossentropy',\n","               metrics = ['accuracy'])\n","  \n","  return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5PFfyFHeJ6Yy","colab_type":"code","outputId":"e0e5a05d-e9f2-4747-b8db-ee119752deba","executionInfo":{"status":"ok","timestamp":1566984131489,"user_tz":-60,"elapsed":1321,"user":{"displayName":"Curtis Irvine","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAjp-X6R5lEtsA5JrpQ1HoZGUfJ5UJM1aTNko51UNU=s64","userId":"05509147058433014282"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["#Defining the batch size and train/validation samples\n","batch_size = 14\n","train_samples = len(images)\n","\n","#This is the augmentation configuration we will use for training \n","train_datagen = ImageDataGenerator(\n","  rescale = 1./255,\n","  shear_range = 0.2,\n","  zoom_range = 0.2,\n","  horizontal_flip = True,\n","  validation_split = 0.2)\n","\n","#Passing the images through augmentation\n","train_generator = train_datagen.flow_from_directory(\n","  TRAIN_PATH,\n","  target_size = (image_width, image_height),\n","  batch_size = batch_size, \n","  class_mode = 'categorical',\n","  subset = 'training')\n","\n","validation_generator = train_datagen.flow_from_directory(TRAIN_PATH,\n","  target_size = (image_width, image_height),\n","  batch_size = batch_size, \n","  class_mode = 'categorical',\n","  subset = 'validation')\n"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Found 5362 images belonging to 8 classes.\n","Found 1337 images belonging to 8 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KvN1i5vuP8cd","colab_type":"code","outputId":"77f75385-749b-4c95-d094-d3cc456a2778","executionInfo":{"status":"ok","timestamp":1566943032640,"user_tz":-60,"elapsed":1660256,"user":{"displayName":"Curtis Irvine","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAjp-X6R5lEtsA5JrpQ1HoZGUfJ5UJM1aTNko51UNU=s64","userId":"05509147058433014282"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["model = create_model()\n","steps_epoch = 5362/batch_size\n","\n","model.fit_generator(train_generator,\n","                   steps_per_epoch = steps_epoch,\n","                   epochs = 10, \n","                   validation_data = validation_generator,\n","                   validation_steps = 1337)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","304/383 [======================>.......] - ETA: 8s - loss: 1.9996 - acc: 0.1586"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EATwn69wHFX_","colab_type":"code","colab":{}},"source":["# Example values:\n","filenames = ['test001','test002','test003','test004']\n","predictions = ['car','cat','fruit','motorbike']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"b_PqnRLKHFYD","colab_type":"code","colab":{}},"source":["# Save results\n","\n","# results go in dataframe: first column is image filename, second column is category name\n","# category names are: airplane, car, cat, dog, flower, fruit, motorbike, person\n","df = pd.DataFrame()\n","df['filename'] = filenames\n","df['label'] = predictions\n","df = df.sort_values(by='filename')\n","\n","df.to_csv('results.csv', header=True, index=False)"],"execution_count":0,"outputs":[]}]}